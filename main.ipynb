{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97372eb4",
   "metadata": {},
   "source": [
    "# Math 4383 Project\n",
    "### Zachary Koenig, Colin Crippen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa0f02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.57.0-cp311-cp311-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.57.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bfdc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "135c6493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1437, 64) (1437, 10)\n",
      "Validation set shape: (360, 64) (360, 10)\n",
      "One-hot encoded y shape: (1797, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- Load the 8x8 digits dataset ---\n",
    "digits = load_digits()\n",
    "\n",
    "# The dataset contains 8x8 images and their corresponding digit labels.\n",
    "# X contains image data and y contains the target labels.\n",
    "X = digits.images      # Shape: (n_samples, 8, 8)\n",
    "y = digits.target      # Shape: (n_samples,)\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "\n",
    "# 1. Flatten the images:\n",
    "#    Convert each 8x8 image into a 1D array of 64 pixels.\n",
    "n_samples = X.shape[0]\n",
    "X_flat = X.reshape(n_samples, -1)   # Now shape is (n_samples, 64)\n",
    "\n",
    "# 2. Normalize the inputs:\n",
    "#    The pixel values in the digits dataset are in the range 0-16.\n",
    "#    Dividing by 16 scales them to the range [0, 1].\n",
    "X_normalized = X_flat / 16.0\n",
    "\n",
    "# 3. One-Hot Encode the Labels:\n",
    "#    There are 10 classes (digits 0-9), so create one-hot encoded vectors.\n",
    "num_classes = 10\n",
    "y_onehot = np.eye(num_classes)[y]\n",
    "\n",
    "# --- Split into Training and Verification (Validation) Sets ---\n",
    "# For example, reserve 20% of the data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_normalized, y_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)  # Should show ~80% of the samples\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)      # Should show ~20% of the samples\n",
    "print(\"One-hot encoded y shape:\", y_onehot.shape)    # Expected: (n_samples, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e30f06",
   "metadata": {},
   "source": [
    "Sigmoid function to enable nonlinear function representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6aa7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Activation functions and their derivatives ---\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Compute the sigmoid activation.\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    \"\"\"Compute the derivative of the sigmoid function.\"\"\"\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax activation for each row of x.\"\"\"\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))  # for numerical stability\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d54b1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "input_size = 8 * 8   # 64 inputs, one per pixel\n",
    "hidden_size = 64       # You can adjust this\n",
    "output_size = 10       # 10 classes for digits 0-9\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 3_000\n",
    "\n",
    "# --- Initialize Weights and Biases ---\n",
    "np.random.seed(459)  # For reproducibility\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c15f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.6896\n",
      "Epoch 100: loss = 2.3001\n",
      "Epoch 200: loss = 2.2968\n",
      "Epoch 300: loss = 2.2881\n",
      "Epoch 400: loss = 2.2638\n",
      "Epoch 500: loss = 2.1985\n",
      "Epoch 600: loss = 2.0486\n",
      "Epoch 700: loss = 1.8062\n",
      "Epoch 800: loss = 1.5489\n",
      "Epoch 900: loss = 1.3400\n",
      "Epoch 1000: loss = 1.1862\n",
      "Epoch 1100: loss = 1.0693\n",
      "Epoch 1200: loss = 0.9719\n",
      "Epoch 1300: loss = 0.8856\n",
      "Epoch 1400: loss = 0.8091\n",
      "Epoch 1500: loss = 0.7424\n",
      "Epoch 1600: loss = 0.6841\n",
      "Epoch 1700: loss = 0.6323\n",
      "Epoch 1800: loss = 0.5855\n",
      "Epoch 1900: loss = 0.5429\n",
      "Epoch 2000: loss = 0.5041\n",
      "Epoch 2100: loss = 0.4691\n",
      "Epoch 2200: loss = 0.4380\n",
      "Epoch 2300: loss = 0.4108\n",
      "Epoch 2400: loss = 0.3872\n",
      "Epoch 2500: loss = 0.3666\n",
      "Epoch 2600: loss = 0.3486\n",
      "Epoch 2700: loss = 0.3329\n",
      "Epoch 2800: loss = 0.3188\n",
      "Epoch 2900: loss = 0.3063\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "num_train_samples = X_train.shape[0]  # Use real number of training samples\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass:\n",
    "    Z1 = np.dot(X_train, W1) + b1       # Input to hidden layer\n",
    "    A1 = sigmoid(Z1)                   # Hidden layer activation\n",
    "    Z2 = np.dot(A1, W2) + b2            # Hidden to output layer\n",
    "    A2 = sigmoid(Z2)                   # Output activation\n",
    "\n",
    "    # Compute Cross-Entropy Loss (adding a small constant for numerical stability)\n",
    "    loss = -np.mean(np.sum(y_train * np.log(A2 + 1e-8), axis=1))\n",
    "    \n",
    "       # Backward pass:\n",
    "    # For softmax and cross-entropy, the gradient simplifies:\n",
    "    dZ2 = A2 - y_train\n",
    "    dW2 = np.dot(A1.T, dZ2) / X_train.shape[0]\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / X_train.shape[0]\n",
    "    \n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_deriv(Z1)\n",
    "    dW1 = np.dot(X_train.T, dZ1) / X_train.shape[0]\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / X_train.shape[0]\n",
    "    \n",
    "    # Update the weights and biases using gradient descent:\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss:.4f}\")\n",
    "\n",
    "\n",
    "# Save the trained weights and biases to disk\n",
    "np.save('W1.npy', W1)\n",
    "np.save('b1.npy', b1)\n",
    "np.save('W2.npy', W2)\n",
    "np.save('b2.npy', b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "538b0882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of x_new: (8, 8)\n",
      "Flattened shape of x_new: (1, 64)\n",
      "Predicted digit: 9\n"
     ]
    }
   ],
   "source": [
    "# --- Display and Test One Training Image ---\n",
    "# Select an image from the training set (e.g., first image)\n",
    "idx = np.random.randint(0, X_val[0].shape)\n",
    "# Since X_train contains flattened images, reshape it back to 8x8 for display.\n",
    "img = X_train[idx].reshape(8, 8)\n",
    "label = np.argmax(y_train[idx])\n",
    "\n",
    "# Save the image array to a file. Note that the file name comes first.\n",
    "np.save(\"test.npy\", img)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Training Image - Digit: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "W1 = np.load('W1.npy')\n",
    "b1 = np.load('b1.npy')\n",
    "W2 = np.load('W2.npy')\n",
    "b2 = np.load('b2.npy')\n",
    "\n",
    "# Load the test image. This image is expected to be an 8x8 array.\n",
    "x_new = np.load('test.npy')\n",
    "print(\"Original shape of x_new:\", x_new.shape)  # Should output: (8, 8)\n",
    "\n",
    "# Flatten the image so that it has shape (1, 64)\n",
    "x_new = x_new.reshape(1, -1)\n",
    "print(\"Flattened shape of x_new:\", x_new.shape)  # Should output: (1, 64)\n",
    "\n",
    "# Perform the forward pass\n",
    "A1_new = sigmoid(np.dot(x_new, W1) + b1)\n",
    "A2_new = sigmoid(np.dot(A1_new, W2) + b2)\n",
    "prediction = np.argmax(A2_new)\n",
    "print(\"Predicted digit:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0a3335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 94.44%\n"
     ]
    }
   ],
   "source": [
    "# --- Perform Predictions on the Test Set Using the Loaded Weights ---\n",
    "# Forward pass:\n",
    "# 1. Compute activations for the hidden layer.\n",
    "Z1 = np.dot(X_val, W1) + b1   # Linear combination for the hidden layer.\n",
    "A1 = sigmoid(Z1)              # Apply sigmoid activation.\n",
    "\n",
    "# 2. Compute activations for the output layer.\n",
    "Z2 = np.dot(A1, W2) + b2       # Linear combination for the output layer.\n",
    "A2 = sigmoid(Z2)              # Output activations.\n",
    "\n",
    "# The predicted class for each sample is the one with the highest activation.\n",
    "predictions = np.argmax(A2, axis=1)\n",
    "true_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate the accuracy of the model on the test set.\n",
    "accuracy = np.mean(predictions == true_labels)\n",
    "print(\"Test set accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
