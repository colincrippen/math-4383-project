{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97372eb4",
   "metadata": {},
   "source": [
    "# Math 4383 Project\n",
    "### Zachary Koenig, Colin Crippen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa0f02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zkoen\\onedrive\\desktop\\txst\\25 - spring\\num analysis ii\\math-4383-project\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8bfdc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "135c6493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1437, 64) (1437, 10)\n",
      "Validation set shape: (360, 64) (360, 10)\n",
      "One-hot encoded y shape: (1797, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- Load the 8x8 digits dataset ---\n",
    "digits = load_digits()\n",
    "\n",
    "# The dataset contains 8x8 images and their corresponding digit labels.\n",
    "# X contains image data and y contains the target labels.\n",
    "X = digits.images      # Shape: (n_samples, 8, 8)\n",
    "y = digits.target      # Shape: (n_samples,)\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "\n",
    "# 1. Flatten the images:\n",
    "#    Convert each 8x8 image into a 1D array of 64 pixels.\n",
    "n_samples = X.shape[0]\n",
    "X_flat = X.reshape(n_samples, -1)   # Now shape is (n_samples, 64)\n",
    "\n",
    "# 2. Normalize the inputs:\n",
    "#    The pixel values in the digits dataset are in the range 0-16.\n",
    "#    Dividing by 16 scales them to the range [0, 1].\n",
    "X_normalized = X_flat / 16.0\n",
    "\n",
    "# 3. One-Hot Encode the Labels:\n",
    "#    There are 10 classes (digits 0-9), so create one-hot encoded vectors.\n",
    "num_classes = 10\n",
    "y_onehot = np.eye(num_classes)[y]\n",
    "\n",
    "# --- Split into Training and Verification (Validation) Sets ---\n",
    "# For example, reserve 20% of the data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_normalized, y_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)  # Should show ~80% of the samples\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)      # Should show ~20% of the samples\n",
    "print(\"One-hot encoded y shape:\", y_onehot.shape)    # Expected: (n_samples, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e30f06",
   "metadata": {},
   "source": [
    "Sigmoid function to enable nonlinear function representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6aa7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Activation functions and their derivatives ---\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Compute the sigmoid activation.\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    \"\"\"Compute the derivative of the sigmoid function.\"\"\"\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax activation for each row of x.\"\"\"\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))  # for numerical stability\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "input_size = 8 * 8   # 64 inputs, one per pixel\n",
    "hidden_size = 64       # You can adjust this\n",
    "output_size = 10       # 10 classes for digits 0-9\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 5_000\n",
    "\n",
    "# --- Initialize Weights and Biases ---\n",
    "np.random.seed(89)  # For reproducibility\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c15f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.6918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: loss = 2.3002\n",
      "Epoch 200: loss = 2.2971\n",
      "Epoch 300: loss = 2.2889\n",
      "Epoch 400: loss = 2.2661\n",
      "Epoch 500: loss = 2.2046\n",
      "Epoch 600: loss = 2.0597\n",
      "Epoch 700: loss = 1.8153\n",
      "Epoch 800: loss = 1.5567\n",
      "Epoch 900: loss = 1.3550\n",
      "Epoch 1000: loss = 1.2054\n",
      "Epoch 1100: loss = 1.0886\n",
      "Epoch 1200: loss = 0.9906\n",
      "Epoch 1300: loss = 0.9037\n",
      "Epoch 1400: loss = 0.8252\n",
      "Epoch 1500: loss = 0.7552\n",
      "Epoch 1600: loss = 0.6936\n",
      "Epoch 1700: loss = 0.6392\n",
      "Epoch 1800: loss = 0.5904\n",
      "Epoch 1900: loss = 0.5463\n",
      "Epoch 2000: loss = 0.5065\n",
      "Epoch 2100: loss = 0.4711\n",
      "Epoch 2200: loss = 0.4400\n",
      "Epoch 2300: loss = 0.4130\n",
      "Epoch 2400: loss = 0.3895\n",
      "Epoch 2500: loss = 0.3691\n",
      "Epoch 2600: loss = 0.3513\n",
      "Epoch 2700: loss = 0.3356\n",
      "Epoch 2800: loss = 0.3216\n",
      "Epoch 2900: loss = 0.3091\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "num_train_samples = X_train.shape[0]  # Use real number of training samples\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass:\n",
    "    Z1 = np.dot(X_train, W1) + b1       # Input to hidden layer\n",
    "    A1 = sigmoid(Z1)                   # Hidden layer activation\n",
    "    Z2 = np.dot(A1, W2) + b2            # Hidden to output layer\n",
    "    A2 = sigmoid(Z2)                   # Output activation\n",
    "\n",
    "    # Compute Cross-Entropy Loss (adding a small constant for numerical stability)\n",
    "    loss = -np.mean(np.sum(y_train * np.log(A2 + 1e-8), axis=1))\n",
    "    \n",
    "       # Backward pass:\n",
    "    # For softmax and cross-entropy, the gradient simplifies:\n",
    "    dZ2 = A2 - y_train\n",
    "    dW2 = np.dot(A1.T, dZ2) / X_train.shape[0]\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / X_train.shape[0]\n",
    "    \n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_deriv(Z1)\n",
    "    dW1 = np.dot(X_train.T, dZ1) / X_train.shape[0]\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / X_train.shape[0]\n",
    "    \n",
    "    # Update the weights and biases using gradient descent:\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss:.4f}\")\n",
    "\n",
    "\n",
    "# Save the trained weights and biases to disk\n",
    "np.save('W1.npy', W1)\n",
    "np.save('b1.npy', b1)\n",
    "np.save('W2.npy', W2)\n",
    "np.save('b2.npy', b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "538b0882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of x_new: (8, 8)\n",
      "Flattened shape of x_new: (1, 64)\n",
      "Predicted digit: 8\n"
     ]
    }
   ],
   "source": [
    "# --- Display and Test One Training Image ---\n",
    "# Select an image from the training set (e.g., first image)\n",
    "idx = np.random.randint(0, X_val[0].shape)\n",
    "# Since X_train contains flattened images, reshape it back to 8x8 for display.\n",
    "img = X_train[idx].reshape(8, 8)\n",
    "label = np.argmax(y_train[idx])\n",
    "\n",
    "# Save the image array to a file. Note that the file name comes first.\n",
    "np.save(\"test.npy\", img)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Training Image - Digit: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "W1 = np.load('W1.npy')\n",
    "b1 = np.load('b1.npy')\n",
    "W2 = np.load('W2.npy')\n",
    "b2 = np.load('b2.npy')\n",
    "\n",
    "# Load the test image. This image is expected to be an 8x8 array.\n",
    "x_new = np.load('test.npy')\n",
    "print(\"Original shape of x_new:\", x_new.shape)  # Should output: (8, 8)\n",
    "\n",
    "# Flatten the image so that it has shape (1, 64)\n",
    "x_new = x_new.reshape(1, -1)\n",
    "print(\"Flattened shape of x_new:\", x_new.shape)  # Should output: (1, 64)\n",
    "\n",
    "# Perform the forward pass\n",
    "A1_new = sigmoid(np.dot(x_new, W1) + b1)\n",
    "A2_new = sigmoid(np.dot(A1_new, W2) + b2)\n",
    "prediction = np.argmax(A2_new)\n",
    "print(\"Predicted digit:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0a3335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 94.72%\n"
     ]
    }
   ],
   "source": [
    "# --- Perform Predictions on the Test Set Using the Loaded Weights ---\n",
    "# Forward pass:\n",
    "# 1. Compute activations for the hidden layer.\n",
    "Z1 = np.dot(X_val, W1) + b1   # Linear combination for the hidden layer.\n",
    "A1 = sigmoid(Z1)              # Apply sigmoid activation.\n",
    "\n",
    "# 2. Compute activations for the output layer.\n",
    "Z2 = np.dot(A1, W2) + b2       # Linear combination for the output layer.\n",
    "A2 = sigmoid(Z2)              # Output activations.\n",
    "\n",
    "# The predicted class for each sample is the one with the highest activation.\n",
    "predictions = np.argmax(A2, axis=1)\n",
    "true_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate the accuracy of the model on the test set.\n",
    "accuracy = np.mean(predictions == true_labels)\n",
    "print(\"Test set accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
